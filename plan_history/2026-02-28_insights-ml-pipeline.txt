PLAN: Insights ML Pipeline Bootstrap
DATE: 2026-02-28
STATUS: completed

CONTEXT:
The insights_generator/ module had all code written (scrapers, NLP processor,
lag detector, event impact analyzer, ML pipeline) but had never been run
end-to-end. Dependencies were not installed, DB tables not created, and several
bugs existed in the feature engineering and model evaluation code. There was no
composite scoring system -- individual signals (injuries, weather, lag, momentum)
were scattered across modules with no unified score for ML to learn from.
Ollama is not installed on this machine; it will be set up on another machine later.

CHANGES:

[2026-02-28] [infra] Installed insights_generator dependencies
  - Ran: pip install -r insights_generator/requirements.txt
  - Installed: feedparser, xgboost, lightgbm (scikit-learn, pandas, numpy already present)
  - Also installed libomp via brew (required by xgboost on macOS)
  - All imports verified working

[2026-02-28] [infra] Initialized insights DB tables in odds.db
  - Ran: python -m insights_generator.cli init-db
  - Created tables: news_headlines, structured_events, market_lag_signals,
    event_market_impacts, ml_predictions, game_scores
  - Verified with: python -m insights_generator.cli status
  - Found 34 pre-existing headlines (all unprocessed, waiting for Ollama)

[2026-02-28] [bugfix] Fixed missing provider_spread feature in features.py
  - File: insights_generator/models/features.py
  - Added _calculate_provider_spread() function that queries the full DataFrame
    for other providers' devigged_prob on the same (game_id, market, side) and
    computes the max absolute spread vs the current provider
  - This was listed in config.yaml features but never computed -- always returned 0
  - Also added 'line' column to the market_history query for correct grouping

[2026-02-28] [bugfix] Fixed broken evaluate_model() in features.py
  - File: insights_generator/models/features.py
  - Old behaviour: compared actual_prob > 0.5 to determine direction -- nonsensical
  - New behaviour: extracts original probability from features_json['current_prob'],
    computes actual_move = actual_prob - original_prob, classifies direction with
    same thresholds as predict() (+/- 0.01)
  - Now also back-fills actual_move, actual_direction, outcome_recorded_at, and
    prediction_correct in the ml_predictions table
  - Returns MAE in addition to accuracy

[2026-02-28] [config] Added scoring configuration
  - Files: config.yaml, insights_generator/config.py
  - Added scoring section to config.yaml with weights (injury=0.25, weather=0.10,
    news_momentum=0.15, market_momentum=0.20, provider_lag=0.20, lineup=0.10),
    lookback_hours=72, max_severity=5, outdoor_leagues
  - Added DEFAULT_CONFIG["scoring"] and get_scoring_config() to config.py

[2026-02-28] [infra] Added game_scores table to insights schema
  - File: insights_generator/schema.sql
  - Columns: game_id, scored_at, injury_score, weather_score, news_momentum_score,
    market_momentum_score, provider_lag_score, lineup_score, composite_score, config_json
  - PK on (game_id, scored_at) to track score evolution over time
  - Indices on composite_score DESC and scored_at

[2026-02-28] [feature] Created AI scoring module (scoring.py)
  - File: insights_generator/scoring.py (new)
  - GameScore dataclass with all scoring dimensions
  - score_game(conn, game_id) -- scores one game across 6 dimensions:
    * injury_score: aggregate severity from structured_events (injury type)
    * weather_score: peak weather severity (outdoor leagues only)
    * news_momentum_score: headline count, saturates at 10
    * market_momentum_score: max price velocity over last 60min
    * provider_lag_score: peak signal_strength from market_lag_signals
    * lineup_score: lineup event count, saturates at 2
  - score_all_upcoming(conn) -- batch scores all future games
  - get_score_features(conn, game_id) -- returns flat dict for ML feature injection
  - All dimensions normalised to 0.0-1.0, composite is weighted sum via config

[2026-02-28] [ml] Wired scoring into ML feature pipeline
  - File: insights_generator/models/features.py
  - build_feature_matrix() now calls get_score_features() for each game_id and
    merges score_injury, score_weather, score_news_momentum, score_market_momentum,
    score_provider_lag, score_lineup, score_composite into the feature vector
  - Gracefully falls back to zeros if scoring module fails

[2026-02-28] [feature] Added 'score' CLI command and '--dry-run' to 'analyze'
  - File: insights_generator/cli.py
  - New command: python -m insights_generator.cli score
    Scores all upcoming games, prints ranked table, stores in game_scores
  - analyze --dry-run: shows queued headlines without calling Ollama
  - analyze (without --dry-run): pre-checks Ollama connectivity, shows clear error
    message and queued headline count if Ollama is unreachable
  - status now shows Game Scores count

[2026-02-28] [bugfix] Improved Ollama error messages in nlp_processor.py
  - File: insights_generator/analyzers/nlp_processor.py
  - ConnectionError: now explains Ollama may not be installed, links to install page
  - Timeout: suggests model may still be loading
  - 404 HTTPError: suggests running "ollama pull <model>"

[2026-02-28] [infra] Created plan_history/ folder
  - Files: plan_history/README.md, plan_history/2026-02-28_insights-ml-pipeline.txt
  - Convention: one .txt file per plan, timestamped changes, enough detail for
    any LLM to cold-start with full context on what's been done
